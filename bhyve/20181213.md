# Attendees

- Marcelo Araujo
- Michael Dexter
- Alexandru Elisei
- Rod Grimes
- Darius Mihai
- Elena Mihailescu
- Patrick Mooney
- Sergiu Weisz
- John Baldwin

# Notes

**Michael Dexter:** I have a lead on a discounted ARMv8 board from
Gigabyte.

**Alexandru Elisei:** This is a ThunderX board, right?

**Michael:** Yes.

**Alexandru:** Is there a way to know which VM a given CPU is running
when an interrupt comes in?

**John Baldwin:** You could add a new MD field to `struct pcpu` via
`PCPU_MD_FIELDS` on arm that you set when entering a guest and clear
when leaving a guest.  You will need to only have it set when
migration and preemption are disabled (`critical_enter` and
`critical_exit`).

**John:** Alex, I need to give you more feedback on the libvmmapi MI /
MD change and will try to do that in the next couple of days.

**John:** Patrick, any update from what you are working on?

**Patrick Mooney:** reworking FreeBSD VM eumlation with an eye towards
live migration

**John:** Elena, how is the current COW work with live migration
going?

**Elena Mihailescu:** Only using guests with wired memory for now to
avoid dealing with problems with swapped out pages.  Am only dealing
with low memory segment for now.  It somewhat works.  A guest with
256MB of RAM works well, but a 1GB guest crashes.  I have some kernel
panics in the guest because some of the pages aren't present, so I am
still debugging it.

*some discussion about questions with managing with the EPT dirty
bits.  Result is that Elena will follow up on the existing thread with
current status and a pointer to the code on github.*

**Michael:** Does anyone beyond Alex need hardware to assist with
their work through Gigabyte?

**John:** ARM specific?

**Michael:** Anything and everything.

**Patrick:** I have a question for Rod on setting max cpus and to
getting to dynamic CPU structures.  Been working on formalizing the
synchronization used by bhyve.  Much of the current practice seems to
depend on freezing all the vCPUs when making changes.  That largely
works for many of the things we care about.  We have a virtio driver
that lets us do some requests in the kernel, but those aren't subject
to vCPU freezing.  Our interface lets us define the max cpus when
creating the VM.  FreeBSD's interface creates the name as one
operation, and it doesn't seem like it would be an easy change to
atomically set the max cpus.

**Rod:** I was planning on delaying structure allocation until the
first thread actually starts up, but at that point max cpus would be
fixed.  I would like to set it during the initial create if possible.

*some more discussion about how to set max_cpus.  General agreement
seems to be we want some way on FreeBSD side to set it and have it be
static and not dynamic when the VM is running.*

*discussion from Patrick about an in-kernel virtio-net accelerator.
Patrick offers to talk about it in more detail on our next call.*

**John:** Let's do our next meeting on Jan 3rd to avoid December 27th.

**Alexandru:** One more question: regarding separating MI from MD in
the bhyve program.  When I have that ready should I post it on
phabricator?

**John:** Sure.  We can start with one big diff to get started and use
that to work on an overall strategy without doing a detailed review.
We can then shift to doing smaller reviews of splitting individual
files as a series of commits.

**Alex:** I think we will need MD versions of bhyverun.c.

**Patrick:** I think if we work on some of the configuration changes
first it might make the split easier and maybe not require separate
command line options, etc.

**Marcelo Araujo:** Working on project for a disk library to support
other disk formats like QCOW2.  I've started working on QCOW2 support.
The library has an interface that looks like a virtual disk.  I can
send out an e-mail of how to use the current repo.  It's not ready for
phabricator yet, but if folks want to look at it and give some
feedback on the design and help with development it would be very
welcome.

**Sergiu Weisz:** I'm going to try to help Marcelo with this.

**Patrick:** We added a change to block_if to toggle write caching
since we use ZFS vols as backing store and wanted flush to be "real".
I think ahci keeps the cache on all the time.  I think NVMe might not
be doing the right thing right now.  There was an issue with async
writes with ZFS volumes and flushing that had a recent fix merged to
ZFS in Illumos.  Might want to check if FreeBSD has that fix.

*some discussion about disk performance and async writes and cache
flushing*

**Marcelo:** Do you have some performance numbers for networking?

**Patrick:** We had to do some work to plumb TSO through our network
stack first, but we use an in-kernel virtio-net driver.  With Linux
guests we see 15 to 20 Gbps, but the Windows virtio-net driver is
terrible.

**Marcelo:** I haven't tested PCI passthrough or netmap.  But using
virtio-net with Linux and FreeBSD guests under FreeBSD I was only
getting 4Gbps.

**Patrick:** For us, doing TSO and checksum offloading on the physical
NIC was a big win.

**Marcelo:** On FreeBSD, tap(4) and if_bridge(4) are some of our
bottlenecks.
